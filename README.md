# ðŸ§  Ollama Local LLM Chatbot (Python)

A lightweight Python chatbot that connects to a locally running LLM via [Ollama](https://ollama.com/). No cloud, no UI â€” just a terminal-based chat powered by models like LLaMA 3, Mistral, or Phi running on your own machine.

## âœ… Features

- Uses any Ollama-supported LLM (e.g. `llama3`, `mistral`, `phi`)
- Simple Python script (run in terminal or IDLE)
- Maintains conversation history for better context
- 100% local â€” no API keys or internet required

## ðŸ›  Requirements

- Python 3.7+
- Ollama installed and running locally

## ðŸ“¦ Installation

1. **Install Ollama**  
   ðŸ‘‰ [Download & install from here](https://ollama.com/download)

2. **Download dependencies**

```bash
pip install requests








